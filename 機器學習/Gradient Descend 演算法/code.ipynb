{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0574f80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "試行第1000次，a為2.1096675206838262，b為0.8097539923224204,mse為0.22254104580342302\n",
      "試行第2000次，a為2.067206887395702，b為1.0980359534544855,mse為0.1356049347531842\n",
      "試行第3000次，a為2.0421456095275787，b為1.2681868384701027,mse為0.10531950798815264\n",
      "試行第4000次，a為2.0273538459634，b為1.3686139465621519,mse為0.09476915022243615\n",
      "試行第5000次，a為2.018623394527926，b為1.4278884195618446,mse為0.09109378352385189\n",
      "試行次數為5691次，最後結果為 a = 2.014783760598431，b = 1.4539572064240953，mse = 0.09007607919129233，模型為 y = 2.014783760598431*x + 1.4539572064240953\n"
     ]
    }
   ],
   "source": [
    "# 用實際的 ( x , y ) 配合 Gradient Descend 演算法來求解迴歸，不用模組\n",
    "\n",
    "\n",
    "import numpy\n",
    "\n",
    "\n",
    "# 1. 先產生 20 組隨機 ( x , y ) 資料，並假設真實模型為 y = 2x + 1\n",
    "\n",
    "# a. x 隨機產生 0 到 10 中間 20 個點\n",
    "\n",
    "x = numpy.linspace(0,10,20)\n",
    "\n",
    "# b. 再利用 y = 2x + 1 + noise 來產生隨機 y , Y 因為是 X 產生，所以也是 numpy array\n",
    "\n",
    "# numpy.random.random(n) 為 產生 n 個 0 ~ 1 之間的隨機數字的產生器\n",
    "\n",
    "y = 2 * x + 1 + numpy.random.random(20)\n",
    "\n",
    "\n",
    "# 2. 定義目標 / 成本函數\n",
    "\n",
    "def object_function(y_prediction , y_true) :\n",
    "\n",
    "    mse = numpy.mean((y_true - y_prediction)**2)\n",
    "\n",
    "    return mse\n",
    "\n",
    "\n",
    "# 3. 設定起始和終止條件\n",
    "\n",
    "# a. 假設參數 a , b 一開始皆為 0\n",
    "\n",
    "a = 0\n",
    "b = 0\n",
    "\n",
    "# b. 假設試行 10000 次 , 學習率為 0.001 , mse 為無限大\n",
    "\n",
    "iteration = 10000\n",
    "learning_rate = 0.001\n",
    "previous_mse = float(\"inf\")\n",
    "\n",
    "# c. 假設終止條件是目標函數差別 < 0.000001\n",
    "\n",
    "mse_threhold = 0.000001\n",
    "\n",
    "\n",
    "# 4. 開始迴圈進行逼近\n",
    "\n",
    "for i in range(iteration) : \n",
    "\n",
    "    y_hat = a * x + b\n",
    "\n",
    "    da = -2 * numpy.mean(x*(y-y_hat))\n",
    "\n",
    "    db = -2 * numpy.mean((y-y_hat))\n",
    "\n",
    "    a = a - learning_rate*da\n",
    "\n",
    "    b = b - learning_rate*db\n",
    "\n",
    "    if (i+1)%1000 == 0 : \n",
    "        \n",
    "        print(f\"試行第{i+1}次，a為{a}，b為{b},mse為{previous_mse}\")\n",
    "\n",
    "    y_hat = a * x + b\n",
    "\n",
    "    new_mse = object_function(y_hat,y)\n",
    "\n",
    "    if previous_mse - new_mse < mse_threhold : \n",
    "\n",
    "        break\n",
    "\n",
    "    previous_mse = new_mse\n",
    "\n",
    "print(f\"試行次數為{i+1}次，最後結果為 a = {a}，b = {b}，mse = {new_mse}，模型為 y = {a}*x + {b}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a792c04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a參數 = [[1.89057145]] , b參數 = [1.50187258] , 模型 R square 為 0.9937832526172294\n"
     ]
    }
   ],
   "source": [
    "# 做一個直接用 scikit learn 套件算迴歸參數的版本\n",
    "\n",
    "\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "\n",
    "# 1. 產生 ( x , y ) 資料\n",
    "\n",
    "# a. 直接自己做\n",
    "\n",
    "# 要記得把 x , y 轉成 2D 陣列，即便只有一排資料，這樣 regression 才能跑\n",
    "\n",
    "# x 要做 reshape(-1,1) , 第一個參數代表選取所有列，第二個是欄 , y 也是一樣 , 但 random 要用 tuple ,\n",
    "\n",
    "# 隨機變數產生可以選 random.random (只會產生 0 到 1 數字) 或 random.uniform (可以自己選上下數字範圍)\n",
    "\n",
    "x = numpy.linspace(0,10,20).reshape(-1,1)\n",
    "\n",
    "y = 2*x + 1 + numpy.random.uniform(-1,1,20).reshape(-1,1)\n",
    "\n",
    "# b. 用模組的方法做\n",
    "\n",
    "# x , y = make_regression(n_samples=20,n_features=1,noise=10,random_state=42)\n",
    "\n",
    "\n",
    "# 2. 做訓練資料集和測試資料集\n",
    "\n",
    "x_test , x_train , y_test , y_train = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "\n",
    "# 3. 進行迴歸\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(x,y)\n",
    "\n",
    "\n",
    "# 4. 產出結果\n",
    "\n",
    "print(f\"a參數 = {model.coef_} , b參數 = {model.intercept_} , 模型 R square 為 {model.score(x_test,y_test)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "65601741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.571\n",
      "Model:                            OLS   Adj. R-squared:                  0.476\n",
      "Method:                 Least Squares   F-statistic:                     5.988\n",
      "Date:                Sun, 17 Aug 2025   Prob (F-statistic):             0.0222\n",
      "Time:                        08:38:06   Log-Likelihood:                -62.836\n",
      "No. Observations:                  12   AIC:                             131.7\n",
      "Df Residuals:                       9   BIC:                             133.1\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        591.2658   1726.740      0.342      0.740   -3314.892    4497.424\n",
      "x1             0.5508      0.315      1.749      0.114      -0.162       1.263\n",
      "x2             0.3579      0.356      1.006      0.341      -0.447       1.163\n",
      "==============================================================================\n",
      "Omnibus:                       10.098   Durbin-Watson:                   1.781\n",
      "Prob(Omnibus):                  0.006   Jarque-Bera (JB):                5.221\n",
      "Skew:                          -1.359   Prob(JB):                       0.0735\n",
      "Kurtosis:                       4.747   Cond. No.                     1.02e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.02e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "[0.55077892 0.35794511] 591.2658321570743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zxzxa\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:430: UserWarning: `kurtosistest` p-value may be inaccurate with fewer than 20 observations; only n=12 observations were given.\n",
      "  return hypotest_fun_in(*args, **kwds)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (12,3) and (8,2) not aligned: 3 (dim 1) != 8 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 83\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# 5. 做樣本外 R square 測試 , OLS 只能用 scikit learn 的 r2_score 來算配適程度\u001b[39;00m\n\u001b[0;32m     81\u001b[0m x_test_set \u001b[38;5;241m=\u001b[39m add_constant(x_test_data)\n\u001b[1;32m---> 83\u001b[0m y_prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_test_data)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_prediction)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(r2_score(y_test))\n",
      "File \u001b[1;32mc:\\Users\\zxzxa\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:409\u001b[0m, in \u001b[0;36mRegressionModel.predict\u001b[1;34m(self, params, exog)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    407\u001b[0m     exog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog\n\u001b[1;32m--> 409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdot(exog, params)\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (12,3) and (8,2) not aligned: 3 (dim 1) != 8 (dim 0)"
     ]
    }
   ],
   "source": [
    "# 改用時間序列資料以及 statsmodels 來做 OLS 迴歸，並產生 p-value 和 F 指標來判斷模型好壞\n",
    "\n",
    "\n",
    "import numpy\n",
    "from statsmodels.api import add_constant , OLS\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# 1. 先載入股價資料\n",
    "\n",
    "stock_price = numpy.array([6449.80,6468.54,6466.58,6445.76,6373.45,6389.45,6340.00,6345.06,6299.19,6329.94,6238.01,6339.39,6362.90,6370.86,6389.77,6388.64,6363.35,6358.91,6309.62,6305.60,6296.79,6297.36,6263.70,6243.76])\n",
    "\n",
    "\n",
    "# 2. 做出時間序列的訓練和測試資料集，為今天和前幾天的資料作為解釋變數\n",
    "\n",
    "# a.先區分訓練集和測試集\n",
    "\n",
    "# 算 array 的元素總數可以先做成切片再來計算，不然只能算一維的\n",
    "\n",
    "N = len(stock_price)\n",
    "stock_price_train = stock_price[:int(numpy.floor(N*0.6)),]\n",
    "stock_price_test = stock_price[int(numpy.floor(N*0.6)):,]\n",
    "\n",
    "# b. 再做成變數資料\n",
    "\n",
    "y_train = []\n",
    "X_1_train = []\n",
    "X_2_train = []\n",
    "\n",
    "N_train = len(stock_price_train)\n",
    "\n",
    "for i in range(N_train-2) : \n",
    "\n",
    "    y_train.append(stock_price_train[i])\n",
    "    X_1_train.append(stock_price_train[i+1])\n",
    "    X_2_train.append(stock_price_train[i+2])\n",
    "\n",
    "y_test = []\n",
    "X_1_test = []\n",
    "X_2_test = []\n",
    "\n",
    "N_test = len(stock_price_test)\n",
    "\n",
    "for i in range(N_test-2) : \n",
    "\n",
    "    y_test.append(stock_price_train[i])\n",
    "    X_1_test.append(stock_price_train[i+1])\n",
    "    X_2_test.append(stock_price_train[i+2])\n",
    "\n",
    "\n",
    "# 3. 把資料合併並加上常數項\n",
    "\n",
    "# stack 的資料來源可以是 list，做完就轉成 numpy array\n",
    "\n",
    "# axis = 0 是往 x 軸展開，基本上就是 append，也可以看做一列一列增加原陣列\n",
    "\n",
    "# axis = 1 or -1 是往 y 軸展開，這個比較特別，會變成欄和列互換，就是 x 軸展開後再做矩陣反轉，陣列的大小會改變\n",
    "\n",
    "x_train_data = numpy.stack((X_1_train,X_2_train),axis=-1)\n",
    "\n",
    "x_train_set = add_constant(x_train_data)\n",
    "\n",
    "x_test_data = numpy.stack((X_1_test,X_2_test),axis=-1)\n",
    "\n",
    "\n",
    "# 4. 做 OLS 回歸 , 結果和 scikit learn 一樣\n",
    "\n",
    "model = OLS(y_train,x_train_set)\n",
    "result = model.fit()\n",
    "\n",
    "model_2 = LinearRegression()\n",
    "model_2.fit(x_train_data,y_train)\n",
    "\n",
    "print(result.summary())\n",
    "print(model_2.coef_,model_2.intercept_)\n",
    "\n",
    "\n",
    "# 5. 做樣本外 R square 測試 , OLS 只能用 scikit learn 的 r2_score 來算配適程度\n",
    "\n",
    "x_test_set = add_constant(x_test_data)\n",
    "\n",
    "y_prediction = model.predict(x_test_data)\n",
    "\n",
    "print(y_prediction)\n",
    "\n",
    "print(r2_score(y_test))\n",
    "\n",
    "print(model_2.score(x_test_data,y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
