{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75e544a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a參數 = [[2.0190522]] , b參數 = [0.85198196] , 模型 R square 為 0.9847933078952412\n"
     ]
    }
   ],
   "source": [
    "# 用 scikit learn 套件算迴歸參數\n",
    "\n",
    "\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "\n",
    "# 1. 產生 ( x , y ) 資料\n",
    "\n",
    "# a. 直接自己做\n",
    "\n",
    "# 要記得把 x , y 轉成 2D 陣列，即便只有一排資料，這樣 regression 才能跑\n",
    "\n",
    "# x 要做 reshape(-1,1) , 第一個參數代表選取所有列，第二個是欄 , y 也是一樣 , 但 random 要用 tuple ,\n",
    "\n",
    "# 隨機變數產生可以選 random.random (只會產生 0 到 1 數字) 或 random.uniform (可以自己選上下數字範圍)\n",
    "\n",
    "x = numpy.linspace(0,10,20).reshape(-1,1)\n",
    "\n",
    "y = 2*x + 1 + numpy.random.uniform(-1,1,20).reshape(-1,1)\n",
    "\n",
    "# b. 用模組的方法做\n",
    "\n",
    "# x , y = make_regression(n_samples=20,n_features=1,noise=10,random_state=42)\n",
    "\n",
    "\n",
    "# 2. 做訓練資料集和測試資料集\n",
    "\n",
    "x_test , x_train , y_test , y_train = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "\n",
    "# 3. 進行迴歸\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(x,y)\n",
    "\n",
    "\n",
    "# 4. 產出結果\n",
    "\n",
    "print(f\"a參數 = {model.coef_} , b參數 = {model.intercept_} , 模型 R square 為 {model.score(x_test,y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff955a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.571\n",
      "Model:                            OLS   Adj. R-squared:                  0.476\n",
      "Method:                 Least Squares   F-statistic:                     5.988\n",
      "Date:                Thu, 21 Aug 2025   Prob (F-statistic):             0.0222\n",
      "Time:                        20:51:37   Log-Likelihood:                -62.836\n",
      "No. Observations:                  12   AIC:                             131.7\n",
      "Df Residuals:                       9   BIC:                             133.1\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        591.2658   1726.740      0.342      0.740   -3314.892    4497.424\n",
      "x1             0.5508      0.315      1.749      0.114      -0.162       1.263\n",
      "x2             0.3579      0.356      1.006      0.341      -0.447       1.163\n",
      "==============================================================================\n",
      "Omnibus:                       10.098   Durbin-Watson:                   1.781\n",
      "Prob(Omnibus):                  0.006   Jarque-Bera (JB):                5.221\n",
      "Skew:                          -1.359   Prob(JB):                       0.0735\n",
      "Kurtosis:                       4.747   Cond. No.                     1.02e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.02e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "[0.55077892 0.35794511] 591.2658321570743\n",
      "0.6457648577517624\n",
      "0.6457648577520916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zxzxa\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:430: UserWarning: `kurtosistest` p-value may be inaccurate with fewer than 20 observations; only n=12 observations were given.\n",
      "  return hypotest_fun_in(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# 改用時間序列資料以及 statsmodels 來做 OLS 迴歸，並產生 p-value 和 F 指標來判斷模型好壞\n",
    "\n",
    "\n",
    "import numpy\n",
    "from statsmodels.api import add_constant , OLS\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# 1. 先載入股價資料\n",
    "\n",
    "stock_price = numpy.array([6449.80,6468.54,6466.58,6445.76,6373.45,6389.45,6340.00,6345.06,6299.19,6329.94,6238.01,6339.39,6362.90,6370.86,6389.77,6388.64,6363.35,6358.91,6309.62,6305.60,6296.79,6297.36,6263.70,6243.76])\n",
    "\n",
    "\n",
    "# 2. 做出時間序列的訓練和測試資料集，為今天和前幾天的資料作為解釋變數\n",
    "\n",
    "# a.先區分訓練集和測試集\n",
    "\n",
    "# 算 array 的元素總數可以先做成切片再來計算，不然只能算一維的\n",
    "\n",
    "N = len(stock_price)\n",
    "stock_price_train = stock_price[:int(numpy.floor(N*0.6))]\n",
    "stock_price_test = stock_price[int(numpy.floor(N*0.6)):]\n",
    "\n",
    "# b. 再做成變數資料\n",
    "\n",
    "y_train = []\n",
    "X_1_train = []\n",
    "X_2_train = []\n",
    "\n",
    "N_train = len(stock_price_train)\n",
    "\n",
    "for i in range(N_train-2) : \n",
    "\n",
    "    y_train.append(stock_price_train[i])\n",
    "    X_1_train.append(stock_price_train[i+1])\n",
    "    X_2_train.append(stock_price_train[i+2])\n",
    "\n",
    "y_test = []\n",
    "X_1_test = []\n",
    "X_2_test = []\n",
    "\n",
    "N_test = len(stock_price_test)\n",
    "\n",
    "for i in range(N_test-2) : \n",
    "\n",
    "    y_test.append(stock_price_train[i])\n",
    "    X_1_test.append(stock_price_train[i+1])\n",
    "    X_2_test.append(stock_price_train[i+2])\n",
    "\n",
    "\n",
    "# 3. 把資料合併並加上常數項\n",
    "\n",
    "# stack 的資料來源可以是 list，做完就轉成 numpy array\n",
    "\n",
    "# x1 和 x2 變數算是欄位，所以要把資料反轉，讓資料變成列，所以用 stack 搭配 axis = 1\n",
    "\n",
    "x_train_data = numpy.stack((X_1_train,X_2_train),axis=1)\n",
    "\n",
    "x_train_set = add_constant(x_train_data)\n",
    "\n",
    "x_test_data = numpy.stack((X_1_test,X_2_test),axis=1)\n",
    "\n",
    "\n",
    "# 4. 做 OLS 回歸 , 結果和 scikit learn 一樣\n",
    "\n",
    "# statsmodel 的 OLS 迴歸\n",
    "\n",
    "model = OLS(y_train,x_train_set)\n",
    "result = model.fit()\n",
    "\n",
    "print(result.summary())\n",
    "\n",
    "# Scikit learn 的 LinearRegression 迴歸\n",
    "\n",
    "model_2 = LinearRegression()\n",
    "model_2.fit(x_train_data,y_train)\n",
    "\n",
    "print(model_2.coef_,model_2.intercept_)\n",
    "\n",
    "\n",
    "# 5. 做樣本外 R square 測試 , OLS 只能用 scikit learn 的 r2_score 來算配適程度\n",
    "\n",
    "# OLS 算 R square ( 要記得加常數項，還有要用 fit 完的結果做預測，不是 model，和 Linear Regression 一樣 )\n",
    "\n",
    "x_test_set = add_constant(x_test_data)\n",
    "\n",
    "y_prediction = result.predict(x_test_set)\n",
    "\n",
    "print(r2_score(y_test,y_prediction))\n",
    "\n",
    "# Linear Regression 算 R square\n",
    "\n",
    "print(model_2.score(x_test_data,y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
