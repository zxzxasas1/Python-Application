{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c308777a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95434492  1.03673227 -0.04773707  0.05665989]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "[0.06592971 0.2994101 ] 0.34040549248996177\n",
      "[np.float64(0.7219881357765339) np.float64(0.7382190026496331)\n",
      " np.float64(0.4880679972525585) np.float64(0.5141611846642938)]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.67      1.00      0.80         2\n",
      "\n",
      "   micro avg       0.75      0.75      0.75         4\n",
      "   macro avg       0.83      0.75      0.73         4\n",
      "weighted avg       0.83      0.75      0.73         4\n",
      "\n",
      "[[0.20039829 1.00704966]] [-0.53125836]\n",
      "[ 1.48031185  1.84709861 -1.79831998 -1.51978565]\n",
      "[0.81461968 0.86378609 0.1420557  0.17949309]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 利用 Logistic Regression 模型來區分資料成兩類\n",
    "\n",
    "\n",
    "\n",
    "# Logistic Regression 特性 : \n",
    "\n",
    "# 1. 本身具有機率的成分，不光是預測是哪個類別，而是預測樣本屬於該類別的 \" 機率 \"\n",
    "\n",
    "# 2. 雖然轉換成機率的 Sigmoid 函數是非線性，但本身模型還是 ax + b 線性，所以算線性模型，比較適合線性資料\n",
    "\n",
    "# 3. 是 ANN 類神經網路裡面一個神經元 , 函數是 Sigmoid 機率函數的特例\n",
    "\n",
    "\n",
    "\n",
    "# a. 下面範例為簡單的四個點，分別在 y 軸的上面和下面，基本上可以用線性的方法來回歸區分出兩類\n",
    "\n",
    "# 1. 確實線性回歸可以做到基本的分類，和 Logistic Regression 一樣\n",
    "\n",
    "# 2. 但是會缺乏機率的結果呈現和解釋，沒有使用 Sigmoid 函數將結果限制在 0 到 1 之間\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy\n",
    "\n",
    "x = numpy.array([[2.5,1.5],[-1.7,2.7],[-1.8,-0.9],[1.6,-1.3]])\n",
    "y = numpy.array([1,1,0,0])\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x,y)\n",
    "\n",
    "y_prediction = model.predict(x)\n",
    "\n",
    "print(y_prediction)\n",
    "\n",
    "y_map = []\n",
    "\n",
    "# 要自己做閥值和區分\n",
    "\n",
    "for item in y_prediction : \n",
    "\n",
    "    if item >= 0.5 : \n",
    "\n",
    "        y_map.append(1)\n",
    "\n",
    "    else : \n",
    "\n",
    "        y_map.append(0)\n",
    "\n",
    "report = classification_report(y,y_map,labels=[\"0\",\"1\"])\n",
    "\n",
    "print(report)\n",
    "\n",
    "\n",
    "\n",
    "# b. 可以發現分類效果還蠻好的 ! 但是 \n",
    "\n",
    "# 1. y_prediction 會超過 0 ~ 1 之間，不像是機率的感覺\n",
    "\n",
    "# 2. 所以要有 Sigmoid 函數的轉換來得到機率，下面做一個用 Sigmoid 函數轉換 y_prediction 的版本\n",
    "\n",
    "\n",
    "\n",
    "x = numpy.array([[2.5,1.5],[-1.7,2.7],[-1.8,-0.9],[1.6,-1.3]])\n",
    "y = numpy.array([1,1,0,0])\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x,y)\n",
    "\n",
    "print(model.coef_,model.intercept_)\n",
    "\n",
    "\n",
    "# 這邊做 Sigmoid 函數，然後要做一個函數來處理 sigmoid 函數的代入值為陣列時也傳回陣列的版本\n",
    "\n",
    "# 基本上這邊因為用 numpy.exp() 所以可以處理陣列，但是如果是 math.exp() 就一定要多做一個函數來處理\n",
    "\n",
    "def sigmoid(u) :  \n",
    "    \n",
    "    value = 1 / (1 + numpy.exp(-u))\n",
    "\n",
    "    return value\n",
    "\n",
    "linear_y = model.predict(x)\n",
    "\n",
    "# 使用 frompyfunc 來將函數轉成可以回傳陣列\n",
    "\n",
    "# 後面兩個參數是每次輸入 1 個值 ( u_value ) 就產生 1 個值 ( sigmoid(u) )，最後形成陣列\n",
    "\n",
    "array_sigmoid = numpy.frompyfunc(sigmoid,1,1)\n",
    "\n",
    "# 使用上有 lamda 的成分，上面 frompyfunc 裡面的 sigmoid 不用放參數，放在下面呼叫時\n",
    "\n",
    "y_prediction = array_sigmoid(linear_y)\n",
    "\n",
    "print(y_prediction)\n",
    "\n",
    "y_map_2 = []\n",
    "\n",
    "for item in y_prediction : \n",
    "\n",
    "    if item >= 0.5 : \n",
    "\n",
    "        y_map_2.append(1)\n",
    "\n",
    "    else : \n",
    "\n",
    "        y_map_2.append(0)\n",
    "\n",
    "report_2 = classification_report(y,y_map_2,labels=[\"0\",\"1\"])\n",
    "\n",
    "print(report_2)\n",
    "\n",
    "\n",
    "\n",
    "# c. 可以發現分類的 y_prediction 確實變成機率\n",
    "\n",
    "# 1. 但是分類的機率會變成有點集中，不太好區分\n",
    "\n",
    "# 2. 因為 Logistic Regression 的機率分布假設和 Linear Regression 不同，因此 Linear Regression 預測值套上 Sigmoid 產生機率會怪怪的\n",
    "\n",
    "# 3. 也因為機率分布假設不同，因此 Logistic Regression 的閥值不會是線性一半一半切分，而是有 log 的非線性特性\n",
    "\n",
    "# 4. Linear Regression 是用 MSE 來求參數，而 Logistic Regression 是用 MLE 來求參數，MLE 才有機率的概念\n",
    "\n",
    "# 5. 下面修正成 Logistic Regression 並且用 Sigmoid 函數看預測值，就可以發現機率就明顯比較分散\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x = numpy.array([[2.5,1.5],[-1.7,2.7],[-1.8,-0.9],[1.6,-1.3]])\n",
    "y = numpy.array([1,1,0,0])\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x,y)\n",
    "\n",
    "print(model.coef_,model.intercept_)\n",
    "\n",
    "\n",
    "# 這邊把 y_prediction 改成自己算，看看中間 Logistic Regression 產生的值和 Sigmoid 函數轉換得到的機率\n",
    "\n",
    "# ( Logistic Regression 的 model.predict 是預設 0.5 以上就視為 1 ，小於就視為 0，這邊一樣比照 )\n",
    "\n",
    "y_logistic = x[:,0]*model.coef_[0,0] + x[:,1]*model.coef_[0,1] + model.intercept_\n",
    "\n",
    "print(y_logistic)\n",
    "\n",
    "# 也可以用 scipy.special 的 expit 來直接求 sigmoid 函數值\n",
    "\n",
    "from scipy.special import expit\n",
    "\n",
    "y_sigmoid = expit(y_logistic)\n",
    "\n",
    "print(y_sigmoid)\n",
    "\n",
    "\n",
    "y_map_3 = []\n",
    "\n",
    "for item in y_sigmoid : \n",
    "\n",
    "    if item >= 0.5 : \n",
    "\n",
    "        y_map_3.append(1)\n",
    "\n",
    "    else : \n",
    "\n",
    "        y_map_3.append(0)\n",
    "\n",
    "report_3 = classification_report(y,y_map_3,labels=[\"0\",\"1\"])\n",
    "\n",
    "print(report_3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
